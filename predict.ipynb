{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected GPU: 0\n",
      "DEVICE is cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from plotting.combine_results import find_files\n",
    "from eval_model import get_model_structure\n",
    "import numpy as np\n",
    "from utils.inference_utils import load_names, load_observed\n",
    "from plotting.plot_utils_bpaitac import histogram\n",
    "from region_identification_utils import get_trial_metrics, identify_regions, summary_stats\n",
    "import pandas as pd\n",
    "from utils.load_model import get_model, get_predictions, load_model\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n",
      "39\n",
      "7\n",
      "199\n",
      "39\n",
      "7\n",
      "199\n",
      "39\n",
      "7\n",
      "False\n",
      "DEVICE is cuda:0\n",
      "998 300 90\n",
      "MODEL STRUCTURE BPcm_250(\n",
      "  (body): Body(\n",
      "    (net): Sequential(\n",
      "      (0): Conv1d(4, 300, kernel_size=(25,), stride=(1,), padding=same)\n",
      "      (1): DialatedConvs(\n",
      "        (net): Sequential(\n",
      "          (0): ResBlock(\n",
      "            (conv_block): Sequential(\n",
      "              (0): Conv1d(300, 300, kernel_size=(3,), stride=(1,), padding=same, dilation=(2,))\n",
      "              (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "          )\n",
      "          (1): ResBlock(\n",
      "            (conv_block): Sequential(\n",
      "              (0): Conv1d(300, 300, kernel_size=(3,), stride=(1,), padding=same, dilation=(4,))\n",
      "              (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "          )\n",
      "          (2): ResBlock(\n",
      "            (conv_block): Sequential(\n",
      "              (0): Conv1d(300, 300, kernel_size=(3,), stride=(1,), padding=same, dilation=(8,))\n",
      "              (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "          )\n",
      "          (3): ResBlock(\n",
      "            (conv_block): Sequential(\n",
      "              (0): Conv1d(300, 300, kernel_size=(3,), stride=(1,), padding=same, dilation=(16,))\n",
      "              (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "          )\n",
      "          (4): ResBlock(\n",
      "            (conv_block): Sequential(\n",
      "              (0): Conv1d(300, 300, kernel_size=(3,), stride=(1,), padding=same, dilation=(32,))\n",
      "              (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "          )\n",
      "          (5): ResBlock(\n",
      "            (conv_block): Sequential(\n",
      "              (0): Conv1d(300, 300, kernel_size=(3,), stride=(1,), padding=same, dilation=(64,))\n",
      "              (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "          )\n",
      "          (6): ResBlock(\n",
      "            (conv_block): Sequential(\n",
      "              (0): Conv1d(300, 300, kernel_size=(3,), stride=(1,), padding=same, dilation=(128,))\n",
      "              (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "          )\n",
      "          (7): ResBlock(\n",
      "            (conv_block): Sequential(\n",
      "              (0): Conv1d(300, 300, kernel_size=(3,), stride=(1,), padding=same, dilation=(256,))\n",
      "              (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "          )\n",
      "          (8): ResBlock(\n",
      "            (conv_block): Sequential(\n",
      "              (0): Conv1d(300, 300, kernel_size=(3,), stride=(1,), padding=same, dilation=(512,))\n",
      "              (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): BPcmHead(\n",
      "    (profile_prediction): ProfileHead(\n",
      "      (bin): Bin()\n",
      "      (deconvolution): Conv1d(300, 90, kernel_size=(25,), stride=(1,), padding=same)\n",
      "      (softmax): Softmax(dim=2)\n",
      "    )\n",
      "    (total_count_prediction): ScalarHeadConvMaxpool(\n",
      "      (net): Sequential(\n",
      "        (0): MaxPool1d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): Conv1d(300, 300, kernel_size=(3,), stride=(1,), padding=same)\n",
      "        (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU()\n",
      "        (4): MaxPool1d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
      "        (5): Conv1d(300, 300, kernel_size=(3,), stride=(1,), padding=same)\n",
      "        (6): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU()\n",
      "        (8): MaxPool1d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
      "        (9): Conv1d(300, 300, kernel_size=(3,), stride=(1,), padding=same)\n",
      "        (10): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (11): ReLU()\n",
      "      )\n",
      "      (out_layers): Sequential(\n",
      "        (0): Flatten(start_dim=1, end_dim=-1)\n",
      "        (1): Linear(in_features=2100, out_features=90, bias=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/gws/nchand/MostafaviLab/bpAITAC/load_model.py:42: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(saved_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE is cuda:0\n",
      "998 300 90\n"
     ]
    }
   ],
   "source": [
    "model1_dir = '/data/nchand/analysis/BPcm_250/BP200_L0_0/'\n",
    "path_model1 = '/data/nchand/analysis/BPcm_250/BP200_L0_0/complete/04-08-2025.15.04/best_model'\n",
    "model2_dir = '/data/nchand/analysis/BPcm_250/BP203_no_seed_L-1_5/'\n",
    "path_model2 = '/data/nchand/analysis/BPcm_250/BP203_no_seed_L-1_5/complete/04-06-2025.18.35/best_model'\n",
    "output_dir = '/data/nchand/analysis/BPcm_250/BP203_200_analysis'\n",
    "model_type = 'BPcm_250'\n",
    "\n",
    "n_celltypes = 90\n",
    "n_filters = 300\n",
    "seq_len = 998\n",
    "model_structure1 = get_model_structure(model_type, n_filters, n_celltypes, seq_len=seq_len)\n",
    "model_structure2 = get_model_structure(model_type, n_filters, n_celltypes, seq_len=seq_len)\n",
    "\n",
    "model_structure = get_model_structure(model_type, n_filters, n_celltypes, seq_len=seq_len)\n",
    "print(path_model1 == path_model2)\n",
    "model1 = load_model(path_model1, model_structure=model_structure1, n_filters=n_filters, verbose=True)\n",
    "model2 = load_model(path_model2, model_structure=model_structure2, n_filters=n_filters, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25207,)\n",
      "(25207, 4, 998)\n"
     ]
    }
   ],
   "source": [
    "cell_names = np.load(\"/data/nchand/ImmGen/mouse/BPprofiles1000/ImmGenATAC1219.peak_matched_in_sorted.sl10004sh-4.celltypes.npy\")\n",
    "\n",
    "b6_seq_files = np.load('/data/mostafavilab/ImgenATAC/F1_chr11_chr16_seq/b6seqs_padded_chr11chr16.npz')\n",
    "print(b6_seq_files['names'].shape)\n",
    "print(b6_seq_files['seqs'].shape)\n",
    "b6_names = b6_seq_files['names']\n",
    "b6_seqs = b6_seq_files['seqs']\n",
    "\n",
    "castseqs_files = np.load('/data/mostafavilab/ImgenATAC/F1_chr11_chr16_seq/castseqs_padded_chr11chr16.npz')\n",
    "castseqs_names = castseqs_files['names']\n",
    "castseqs_seqs = castseqs_files['seqs']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "def pred(model, onehot_seq, n_celltypes=90, batch_size=100):\n",
    "    torch.cuda.empty_cache()\n",
    "    model.to(DEVICE)\n",
    "    counts = torch.zeros((0, n_celltypes)).to(DEVICE)\n",
    "    onehot_seq = onehot_seq.astype(np.float32)\n",
    "    seq = torch.from_numpy(onehot_seq)\n",
    "\n",
    "    # Calculate number of batches (ceiling division)\n",
    "    n_batches = (len(seq) + batch_size - 1) // batch_size\n",
    "    \n",
    "    # Process all batches including the final partial batch\n",
    "    for i in tqdm(range(n_batches)):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min((i + 1) * batch_size, len(seq))\n",
    "        X = seq[start_idx:end_idx]\n",
    "        bias = torch.zeros((X.shape[0], X.shape[2]))\n",
    "        with torch.no_grad():\n",
    "            profile, scalar = model(X.to(DEVICE), bias.to(DEVICE))\n",
    "            counts = torch.cat((counts, scalar), 0)\n",
    "    \n",
    "    return counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 253/253 [00:15<00:00, 16.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25207, 4, 998)\n",
      "torch.Size([25207, 90])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 253/253 [00:14<00:00, 16.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25207, 4, 998)\n",
      "torch.Size([25207, 90])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "b6_counts_model1 = pred(model1, b6_seqs)\n",
    "print(b6_seqs.shape)\n",
    "print(b6_counts_model1.shape)\n",
    "\n",
    "b6_counts_model2 = pred(model2, b6_seqs)\n",
    "print(b6_seqs.shape)\n",
    "print(b6_counts_model2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING validation data loader\n",
      "batch num 0\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.7222)\n",
      "batch num 1\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.7402)\n",
      "batch num 2\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.7455)\n",
      "batch num 3\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.7498)\n",
      "batch num 4\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.7365)\n",
      "batch num 5\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.7263)\n",
      "batch num 6\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.7255)\n",
      "batch num 7\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.7307)\n",
      "batch num 8\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.7261)\n",
      "batch num 9\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.7267)\n",
      "batch num 10\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.7190)\n",
      "batch num 11\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.7207)\n",
      "batch num 12\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.7113)\n",
      "batch num 13\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.7095)\n",
      "batch num 14\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.7058)\n",
      "batch num 15\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.7065)\n",
      "batch num 16\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.7050)\n",
      "batch num 17\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.7020)\n",
      "batch num 18\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6993)\n",
      "batch num 19\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6965)\n",
      "batch num 20\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6961)\n",
      "batch num 21\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6982)\n",
      "batch num 22\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6944)\n",
      "batch num 23\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6933)\n",
      "batch num 24\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6902)\n",
      "batch num 25\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6919)\n",
      "batch num 26\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6911)\n",
      "batch num 27\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6929)\n",
      "batch num 28\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6927)\n",
      "batch num 29\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6913)\n",
      "batch num 30\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6921)\n",
      "batch num 31\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6934)\n",
      "batch num 32\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6948)\n",
      "batch num 33\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6920)\n",
      "batch num 34\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6895)\n",
      "batch num 35\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6912)\n",
      "batch num 36\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6921)\n",
      "batch num 37\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6932)\n",
      "batch num 38\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6937)\n",
      "batch num 39\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6950)\n",
      "batch num 40\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6956)\n",
      "batch num 41\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6952)\n",
      "batch num 42\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6959)\n",
      "batch num 43\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6962)\n",
      "batch num 44\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6963)\n",
      "batch num 45\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6954)\n",
      "batch num 46\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6963)\n",
      "batch num 47\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6964)\n",
      "batch num 48\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6968)\n",
      "batch num 49\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6969)\n",
      "batch num 50\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6965)\n",
      "batch num 51\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6972)\n",
      "batch num 52\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6973)\n",
      "batch num 53\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6976)\n",
      "batch num 54\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6967)\n",
      "batch num 55\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6964)\n",
      "batch num 56\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6963)\n",
      "batch num 57\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6950)\n",
      "batch num 58\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6954)\n",
      "batch num 59\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6941)\n",
      "batch num 60\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6940)\n",
      "batch num 61\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6940)\n",
      "batch num 62\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6944)\n",
      "batch num 63\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6950)\n",
      "batch num 64\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6955)\n",
      "batch num 65\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6960)\n",
      "batch num 66\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6965)\n",
      "batch num 67\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6972)\n",
      "batch num 68\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6965)\n",
      "batch num 69\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6965)\n",
      "batch num 70\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6969)\n",
      "batch num 71\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6976)\n",
      "batch num 72\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6979)\n",
      "batch num 73\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6964)\n",
      "batch num 74\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6966)\n",
      "batch num 75\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6967)\n",
      "batch num 76\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6966)\n",
      "batch num 77\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6968)\n",
      "batch num 78\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6964)\n",
      "batch num 79\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6963)\n",
      "batch num 80\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6966)\n",
      "batch num 81\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6970)\n",
      "batch num 82\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6974)\n",
      "batch num 83\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6972)\n",
      "batch num 84\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6974)\n",
      "batch num 85\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6976)\n",
      "batch num 86\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6979)\n",
      "batch num 87\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6977)\n",
      "batch num 88\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6983)\n",
      "batch num 89\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6984)\n",
      "batch num 90\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6986)\n",
      "batch num 91\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6986)\n",
      "batch num 92\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6979)\n",
      "batch num 93\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6982)\n",
      "batch num 94\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6987)\n",
      "batch num 95\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6989)\n",
      "batch num 96\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6993)\n",
      "batch num 97\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.6998)\n",
      "batch num 98\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.7000)\n",
      "batch num 99\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.7000)\n",
      "batch num 100\n",
      "bias shape before it goes into model torch.Size([20, 998])\n",
      "jsd mean tensor(0.7002)\n",
      "batch num 101\n",
      "bias shape before it goes into model torch.Size([20, 998])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m train_loader, val_loader, test_loader \u001b[38;5;241m=\u001b[39m load_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/data/nchand/ImmGen/mouse/BPprofiles1000/memmaped/complete_shallow_deprotinated_bias_quantile_normalized_4.1.25/memmap/info.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m      3\u001b[0m eval_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mget_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_celltypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m90\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_scalar_prediction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                \u001b[49m\u001b[43mget_scalar_observed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_profile_observed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_profile_prediction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbin_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel2_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m998\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_out_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MostafaviLab/bpAITAC/load_model.py:153\u001b[0m, in \u001b[0;36mget_predictions\u001b[0;34m(model, train_loader, val_loader, test_loader, n_celltypes, get_scalar_prediction, get_profile_prediction, get_scalar_observed, get_profile_observed, eval_set, bin_size, model_dir, saved_file_name, batch_size, save_pred, ocr_start, ocr_end, seq_len, seq_out_len)\u001b[0m\n\u001b[1;32m    151\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m get_profile_observed:\n\u001b[1;32m    152\u001b[0m     profile_obs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((profile_obs, bp_counts\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mFloatTensor)), \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjsd mean\u001b[39m\u001b[38;5;124m'\u001b[39m, torch\u001b[38;5;241m.\u001b[39mmean(\u001b[43mJSD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile_obs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m375\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m625\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m    154\u001b[0m np\u001b[38;5;241m.\u001b[39msavez(file_path, scalar_obs\u001b[38;5;241m=\u001b[39mscalar_obs, scalar_pred\u001b[38;5;241m=\u001b[39mscalar_pred, profile_obs\u001b[38;5;241m=\u001b[39mprofile_obs, profile_pred\u001b[38;5;241m=\u001b[39mprofile_pred,)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved\u001b[39m\u001b[38;5;124m'\u001b[39m, file_path)\n",
      "File \u001b[0;32m~/MostafaviLab/bpAITAC/functions.py:34\u001b[0m, in \u001b[0;36mJSD\u001b[0;34m(P, Q, reduction)\u001b[0m\n\u001b[1;32m     31\u001b[0m p \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m/\u001b[39mnormp \u001b[38;5;66;03m# expected dimension (N, 90, 1000) the sum gets broadcast across the sequence length\u001b[39;00m\n\u001b[1;32m     32\u001b[0m q \u001b[38;5;241m=\u001b[39m q\u001b[38;5;241m/\u001b[39mnormq\n\u001b[0;32m---> 34\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m plog \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mlog2()\n\u001b[1;32m     36\u001b[0m qlog \u001b[38;5;241m=\u001b[39m q\u001b[38;5;241m.\u001b[39mlog2()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from utils.inference_utils import load_data\n",
    "train_loader, val_loader, test_loader = load_data('/data/nchand/ImmGen/mouse/BPprofiles1000/memmaped/complete_shallow_deprotinated_bias_quantile_normalized_4.1.25/memmap/info.txt', batch_size=20)\n",
    "eval_set='validation'\n",
    "get_predictions(model2, train_loader=train_loader, val_loader=val_loader, test_loader=test_loader, n_celltypes=90, get_scalar_prediction=False, \n",
    "                get_scalar_observed=False, get_profile_observed=True, get_profile_prediction=True, eval_set=eval_set, bin_size=1, model_dir=model2_dir, seq_len=998, seq_out_len=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.array_equal(b6_counts_model1.cpu(), b6_counts_model2.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp6_save_path = '/data/mostafavilab/ForAlex/F1_experiment/b6seqs_padded_chr11chr16_predictions_qnorm_BP200_203.npz'\n",
    "np.savez(bp6_save_path, seqs=b6_seqs, names=b6_names, cellnames=cell_names, lambda0_pred=b6_counts_model1.cpu(), lambdap5_pred=b6_counts_model2.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                          | 0/253 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 253/253 [00:15<00:00, 16.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25207, 4, 998)\n",
      "torch.Size([25207, 90])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 253/253 [00:15<00:00, 16.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25207, 4, 998)\n",
      "torch.Size([25207, 90])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "castseqs_counts_model1 = pred(model1, castseqs_seqs)\n",
    "print(castseqs_seqs.shape)\n",
    "print(castseqs_counts_model1.shape)\n",
    "\n",
    "castseqs_counts_model2 = pred(model2, castseqs_seqs)\n",
    "print(castseqs_seqs.shape)\n",
    "print(castseqs_counts_model2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.array_equal(castseqs_counts_model1.cpu(),castseqs_counts_model2.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "castseqs_save_path = '/data/mostafavilab/ForAlex/F1_experiment/castseqs_padded_chr11chr16_predictions_qnorm_BP200_203.npz'\n",
    "np.savez(castseqs_save_path, seqs=castseqs_seqs, names=castseqs_names, cellnames=cell_names, lambda0_pred=castseqs_counts_model1.cpu(), lambdap5_pred=castseqs_counts_model2.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seqs', 'names', 'cellnames', 'lambda0_pred', 'lambdap5_pred']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('/data/mostafavilab/ForAlex/F1_experiment/castseqs_padded_chr11chr16_predictions_qnorm_BP200_203.npz').files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "test =np.load(castseqs_save_path)\n",
    "model1_p = test['lambda0_pred']\n",
    "model2_p = test['lambdap5_pred']\n",
    "\n",
    "print(np.array_equal(model1_p,model2_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing outputs of profile prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from plotting.combine_results import find_files\n",
    "from eval_model import get_model_structure\n",
    "import numpy as np\n",
    "from utils.inference_utils import load_names, load_observed\n",
    "from plotting.plot_utils_bpaitac import histogram\n",
    "from utils.region_identification_utils import get_trial_metrics, identify_regions, summary_stats\n",
    "import pandas as pd\n",
    "from l, get_predictions, load_model\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from plotting.plot_results import plot_profile\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n",
      "39\n",
      "7\n",
      "DEVICE is cuda:3\n",
      "998 300 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/gws/nchand/MostafaviLab/bpAITAC/load_model.py:42: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(saved_model_path))\n"
     ]
    }
   ],
   "source": [
    "n_celltypes = 90\n",
    "n_filters = 300\n",
    "seq_len = 998\n",
    "model_type = 'BPcm_250'\n",
    "\n",
    "model_name = 'BP200_L-1_5'\n",
    "model_dir_3 = '/homes/gws/nchand/MostafaviLab/results/BPcm_250/BP200_sample_L-1_5/complete/03-31-2025.16.07/best_loss_model.pth'\n",
    "model_structure3 = get_model_structure(model_type, n_filters, n_celltypes, seq_len=seq_len)\n",
    "model = load_model(model_dir_3, model_structure=model_structure3, n_filters=n_filters, verbose=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# grab some test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file name /data/nchand/ImmGen/mouse/BPprofiles1000/memmaped/complete_bias_corrected_normalized_3.7.23/memmap/test.onehot.dat\n",
      "file name /data/nchand/ImmGen/mouse/BPprofiles1000/memmaped/complete_bias_corrected_normalized_3.7.23/memmap/test.bp_counts.dat\n",
      "file name /data/nchand/ImmGen/mouse/BPprofiles1000/memmaped/complete_bias_corrected_normalized_3.7.23/memmap/test.total_counts.dat\n",
      "file name /data/nchand/ImmGen/mouse/BPprofiles1000/memmaped/complete_bias_corrected_normalized_3.7.23/memmap/test.bias.dat\n"
     ]
    }
   ],
   "source": [
    "info_file = '/data/nchand/ImmGen/mouse/BPprofiles1000/memmaped/complete_bias_corrected_normalized_3.7.23/memmap/info.txt'\n",
    "onehot_seqs = load_observed(info_file, dataset_type='test', data_name='onehot')\n",
    "bp_counts = load_observed(info_file, dataset_type='test', data_name='bp_counts')\n",
    "total_counts = load_observed(info_file, dataset_type='test', data_name='total_counts')\n",
    "bias = load_observed(info_file, dataset_type='test', data_name='bias')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find very open region and celltype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3977,)\n"
     ]
    }
   ],
   "source": [
    "possible_idx = np.argwhere(np.max(total_counts,axis=1)>500)[:, 0]\n",
    "print(possible_idx.shape)\n",
    "\n",
    "idx = possible_idx[30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare pred to actual for bp counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_single_seq(model, onehot_seqs, bias, seq_idx):\n",
    "    idx = seq_idx\n",
    "    X = onehot_seqs[idx:idx+1]\n",
    "    X = X.transpose(0, 2, 1)\n",
    "    print(X.shape)\n",
    "    bias = bias[idx:idx+1, 0, :]\n",
    "    bias = torch.from_numpy(bias)\n",
    "    print('bias shape', bias.shape)\n",
    "    # bias = torch.zeros((X.shape[0], X.shape[2]))\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    model.to(DEVICE)\n",
    "    X = X.astype(np.float32)\n",
    "    X = torch.from_numpy(X)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        profile, scalar = model(X.to(DEVICE), bias.to(DEVICE))\n",
    "    \n",
    "    return profile.cpu(), scalar.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 998)\n",
      "bias shape torch.Size([1, 998])\n"
     ]
    }
   ],
   "source": [
    "profile, scalar = pred_single_seq(model, onehot_seqs=onehot_seqs, bias=bias, seq_idx=idx)\n",
    "pred()\n",
    "profile = profile.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[17.6067, 21.8778, 11.5930, 10.0835, 12.3181, 14.4984, 11.8603,  8.4140,\n",
       "         16.0912, 10.0619, 11.8849, 11.5739, 14.2535, 10.3016,  8.9254, 13.0301,\n",
       "         10.7061, 11.7486, 15.0419, 14.9377, 13.2589, 12.0105, 13.4672, 11.5037,\n",
       "         10.4869, 33.0868, 16.7306, 13.0907,  9.3825,  7.1716,  9.6076,  7.9272,\n",
       "          6.4446,  0.0000, 26.1345,  9.2177, 12.5881, 28.0891, 15.1897, 24.4267,\n",
       "          8.6167, 13.5006,  9.4757,  7.7642,  9.2850, 23.0289, 20.1094,  7.9458,\n",
       "          8.7230,  7.9583, 10.3213,  9.8266,  9.7434, 13.2195, 14.2532, 13.7673,\n",
       "          0.0000,  7.2588, 11.2509, 14.3758, 16.7616, 13.2703, 18.1315, 13.8629,\n",
       "         16.5219, 33.4187, 12.2921, 12.7030, 10.2662, 11.6177, 13.9978, 10.3168,\n",
       "         12.9551, 12.8454, 15.4602, 12.8335, 14.8131, 11.0897, 13.9049,  7.9625,\n",
       "         13.5324,  7.9548,  8.1671, 20.3369, 16.9789, 15.0423, 29.1560, 19.9712,\n",
       "         21.4915, 13.4858]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell idx 25\n",
      "(250,)\n",
      "profile shape (250,)\n",
      "saved at  test_BP200_L-1_5_idx249.png\n"
     ]
    }
   ],
   "source": [
    "# find most open celltype:\n",
    "cell_idx = np.argmax(total_counts[idx])\n",
    "print('cell idx', cell_idx)\n",
    "\n",
    "bp_counts_center = bp_counts[idx, cell_idx, 375:625]\n",
    "bp_distribution = bp_counts_center / np.sum(bp_counts_center)\n",
    "print(bp_distribution.shape)\n",
    "print('profile shape', profile[0, cell_idx].shape)\n",
    "\n",
    "title = f'test_{model_name}_idx{idx}'\n",
    "outpath = title + '.png'\n",
    "plot_profile(bp_distribution, profile[0, cell_idx], title=title, out_path=outpath)\n",
    "print('saved at ', outpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-tac",
   "language": "python",
   "name": "ai-tac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
